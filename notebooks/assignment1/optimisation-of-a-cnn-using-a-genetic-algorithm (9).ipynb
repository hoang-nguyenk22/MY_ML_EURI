{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1022626,"sourceType":"datasetVersion","datasetId":562468}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Optimisation of a CNN with a Genetic Algorithm\nThis section implements a genetic algorithm (GA) to optimize the hyperparameters of a Convolutional Neural Network (CNN). The goal is to find the best combination of hyperparameters (e.g., number of filters, dense units, learning rate, batch size) that maximizes the validation accuracy of the CNN.\n## Encoding of chromosomes\nEach chromosome represents a potential solution (a set of hyperparameters) and is encoded as a dictionary. The keys of the dictionary correspond to the hyperparameters being optimized, and the values are the specific settings for those hyperparameters. The space of possible values is not continuous, but discrete. They are chosen in a set of allowed values. The parameters, along with their allowed values are : \n* filters: Number of filters in the convolutional layers. Allowed values : [16, 32, 64, 128]\n* dense_units: Number of neurons in the fully connected (dense) layer. Allowed values : [32, 64, 128]\n* lr: Learning rate for the optimizer. Allowed values : [1e-4, 1e-3, 1e-2, 1e-1]\n* batch_size: Number of samples processed in one forward/backward pass during training. Allowed values : [16, 32, 64, 128]\n* dropout: Dropout rate. Allowed values : [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n> \nThere is a total of $4\\times 3\\times 4 \\times 4 \\times 6 = 1152$ possible chromosome.\n>\n\nExample of a chromosome : {'filters': 32, 'dense_units': 64, 'lr': 0.001, 'batch_size': 64, 'dropout': 0.2}\n\n*It would have also been possible to represent each chromosome as a bit string. However, in Python, dictionnaries are computationnaly more efficient than lists/strings, so I chose not to represent them as bit strings.*\n\n## Crossing function\n\nThe chosen crossover strategy is a uniform crossover. For each hyperparameter, the child inherits the value from one of the two parents, chosen at random.\n\n**Example :**\n\nParent 1 : {'filters': 32, 'dense_units': 64, 'lr': 0.001, 'batch_size': 64}\n\nParent 2 : {'filters': 64, 'dense_units': 128, 'lr': 0.0001, 'batch_size': 32}\n\nChild : {'filters': 32, 'dense_units': 128, 'lr': 0.001, 'batch_size': 32}\n\n## Mutation function\n\nEach hyperparameter in the chromosome has a small probability (mutation_rate) of being mutated.\nIf a hyperparameter is selected for mutation, its value is replaced with a new random value from the predefined list of possible values.\n\n*In this notebook, we will use mutation_rate = 0.1*\n\n**Example :**\n\nOriginal chromosome : {'filters': 32, 'dense_units': 64, 'lr': 0.001, 'batch_size': 64}\n\nMutated chromosome : {'filters': 64, 'dense_units': 64, 'lr': 0.001, 'batch_size': 128}\n","metadata":{}},{"cell_type":"code","source":"################################### IMPORTS ########################################################\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport os\nimport pandas as pd\nimport random\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom pathlib import Path\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-07T06:37:07.001435Z","iopub.execute_input":"2025-03-07T06:37:07.001771Z","iopub.status.idle":"2025-03-07T06:37:11.933441Z","shell.execute_reply.started":"2025-03-07T06:37:07.001745Z","shell.execute_reply":"2025-03-07T06:37:11.932395Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"################################## DATASET IMPORT AND TRANSFORMATION ##################################\n\nclass ChestXRayDataset(Dataset):\n    def __init__(self, img_dir, csv_path, transform=None, dataset_type=\"TRAIN\", max_samples=None):\n        \"\"\"\n        Args:\n            img_dir (str): Chemin vers le dossier contenant les images.\n            csv_path (str): Chemin vers le fichier CSV contenant les métadonnées.\n            transform (callable, optional): Transformations à appliquer aux images.\n            dataset_type (str): \"TRAIN\" ou \"TEST\" pour charger les données d'entraînement ou de test.\n            max_samples (int, optional): Nombre maximal d'échantillons à charger.\n        \"\"\"\n        self.img_dir = img_dir\n        self.transform = transform\n        self.metadata = pd.read_csv(csv_path)\n        \n        # Filter the data (TRAIN or TEST)\n        self.metadata = self.metadata[self.metadata['Dataset_type'] == dataset_type]\n        \n        # We can limit the number of samples if needed\n        if max_samples is not None:\n            self.metadata = self.metadata[:max_samples]\n        \n        # List of images and labels path\n        self.image_paths = [os.path.join(img_dir, img_name) for img_name in self.metadata['X_ray_image_name']]\n        self.labels = self.metadata['Label'].apply(lambda x: 1 if x == 'Pnemonia' else 0).values  # Exemple de conversion d'étiquettes\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.image_paths[idx]\n        image = Image.open(img_path).convert('RGB')  # Convertir en RGB pour les modèles CNN\n        label = self.labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((64, 64)),  # Redimensionner les images à 64x64\n    transforms.RandomHorizontalFlip(),  # Augmentation de données : retournement horizontal aléatoire\n    transforms.ToTensor(),  # Convertir en tenseur\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation\n])\n\ntest_transforms = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ndata_path = Path('/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset')\ntraining_folder_path = Path('/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train')\ntesting_folder_path = Path('/kaggle/input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test')\ncsv_path = \"/kaggle/input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\"\n\ntrain_dataset = ChestXRayDataset(img_dir=training_folder_path,\n                                  csv_path=csv_path,\n                                  transform=train_transforms,\n                                  dataset_type=\"TRAIN\",max_samples=4000)\ntest_dataset = ChestXRayDataset(img_dir=testing_folder_path,\n                                 csv_path=csv_path,\n                                 transform=test_transforms,\n                                 dataset_type=\"TEST\",max_samples=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T06:37:14.718813Z","iopub.execute_input":"2025-03-07T06:37:14.719336Z","iopub.status.idle":"2025-03-07T06:37:14.801409Z","shell.execute_reply.started":"2025-03-07T06:37:14.719301Z","shell.execute_reply":"2025-03-07T06:37:14.800616Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"################################### CNN and EVALUATION MODEL #################################################\n\nclass SimpleCNN(nn.Module):\n    def __init__(self, filters=32, dense_units=128, num_classes=2):\n        \"\"\"\n        Args:\n            filters (int): Nombre de filtres dans la première couche de convolution.\n            dense_units (int): Nombre de neurones dans la couche dense.\n            num_classes (int): Nombre de classes de sortie.\n        \"\"\"\n        super(SimpleCNN, self).__init__()\n        \n        # Convolution layers\n        self.conv1 = nn.Conv2d(3, filters, kernel_size=3, stride=1, padding=1) # 3 inputs (RGB)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.conv2 = nn.Conv2d(filters, filters * 2, kernel_size=3, stride=1, padding=1)\n        \n        # Dense layers\n        self.fc1 = nn.Linear(filters * 2 * 16 * 16, dense_units)\n        self.fc2 = nn.Linear(dense_units, num_classes)\n    \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, self.num_flat_features(x))\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n    \n    def num_flat_features(self, x):\n        size = x.size()[1:]\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n\n\ndef evaluate_model(hparams, train_dataset, test_dataset, epochs=5):\n    \"\"\"\n    Entraîne et évalue un modèle CNN avec les hyperparamètres donnés.\n    \n    Args:\n        hparams (dict): Hyperparamètres du modèle.\n        train_loader (DataLoader): DataLoader pour l'entraînement.\n        test_loader (DataLoader): DataLoader pour le test.\n        epochs (int): Nombre d'epochs pour l'entraînement.\n    \n    Returns:\n        float: Précision sur l'ensemble de test.\n    \"\"\"\n    # Loading of the train and test datas based on the given chromosome's batch_size\n    train_loader = DataLoader(train_dataset, batch_size=hparams['batch_size'], shuffle=True)\n    test_loader = DataLoader(test_dataset, batch_size=hparams['batch_size'], shuffle=False)\n    \n    # Creation of the model with the hyperparameters of the given chromosome\n    model = SimpleCNN(\n        filters=hparams['filters'],\n        dense_units=hparams['dense_units'],\n        num_classes=2  # 2 classes : \"Normal\" et \"Pneumonia\"\n    )\n    \n    # Definition of the loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=hparams['lr'])\n    \n    # Training of the model\n    for epoch in range(epochs):\n        model.train()\n        for images, labels in train_loader:\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n    \n    # Evaluation of the model based on tests\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    \n    accuracy = 100 * correct / total\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T06:37:18.815057Z","iopub.execute_input":"2025-03-07T06:37:18.815409Z","iopub.status.idle":"2025-03-07T06:37:18.826514Z","shell.execute_reply.started":"2025-03-07T06:37:18.815379Z","shell.execute_reply":"2025-03-07T06:37:18.825426Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"################################## CHROMOSOME DEFINITION ##################################\n\nfilters_list = [16, 32, 64, 128]\ndense_units_list = [32, 64, 128]\nlr_list = [1e-4, 1e-3, 1e-2, 1e-1]\nbatch_size_list = [16, 32, 64, 128]\ndropout_list = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n\ndef initialize_chromosome(filters_list,dense_units_list,lr_list,batch_size_list,dropout_list):\n    chromosome = {\n        'filters': random.choice(filters_list),\n        'dense_units': random.choice(dense_units_list),\n        'lr': random.choice(lr_list),\n        'batch_size': random.choice(batch_size_list),\n        'dropout': random.choice(dropout_list)\n    }\n    return chromosome","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T06:37:24.727880Z","iopub.execute_input":"2025-03-07T06:37:24.728225Z","iopub.status.idle":"2025-03-07T06:37:24.733866Z","shell.execute_reply.started":"2025-03-07T06:37:24.728198Z","shell.execute_reply":"2025-03-07T06:37:24.732880Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"################################## CROSSOVER AND MUTATION DEFINITION ##################################\n\ndef crossover(parent1, parent2):\n    child = {}\n    for key in parent1:\n        # Randomly chose a gene of parent1 or parent2\n        child[key] = random.choice([parent1[key], parent2[key]])\n    return child\n\ndef mutate(chromosome, filters_list,dense_units_list,lr_list,batch_size_list,dropout_list, mutation_rate=0.1):\n    mutated_chromosome = chromosome.copy()\n    for key in mutated_chromosome:\n        if random.random() < mutation_rate:  #We apply a mutation with a mutation_rate probability\n            if key == 'filters':\n                mutated_chromosome[key] = random.choice(filters_list)\n            elif key == 'dense_units':\n                mutated_chromosome[key] = random.choice(dense_units_list)\n            elif key == 'lr':\n                mutated_chromosome[key] = random.choice(lr_list)\n            elif key == 'batch_size':\n                mutated_chromosome[key] = random.choice(batch_size_list)\n            elif key == 'dropout':\n                mutated_chromosome[key] = random.choice(dropout_list)\n    return mutated_chromosome","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T06:37:28.959176Z","iopub.execute_input":"2025-03-07T06:37:28.959491Z","iopub.status.idle":"2025-03-07T06:37:28.966200Z","shell.execute_reply.started":"2025-03-07T06:37:28.959465Z","shell.execute_reply":"2025-03-07T06:37:28.965125Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"################################## GENETIC ALGORITHM ##################################\n\n\ndef genetic_algorithm(train_dataset, test_dataset, filters_list,dense_units_list,lr_list,batch_size_list,dropout_list, population_size=10, generations=5, mutation_rate=0.1):\n    \"\"\"\n    Algorithme génétique pour optimiser les hyperparamètres du modèle CNN.\n    \n    Args:\n        train_loader (DataLoader): DataLoader pour l'entraînement.\n        test_loader (DataLoader): DataLoader pour le test.\n        population_size (int): Taille de la population.\n        generations (int): Nombre de générations.\n        mutation_rate (float): Taux de mutation.\n    \n    Returns:\n        dict: Meilleurs hyperparamètres trouvés.\n    \"\"\"\n    target_score = 0.95\n    best_scores = []\n    mean_scores = []\n    \n    # Initialization of the population\n    population = [initialize_chromosome(filters_list,dense_units_list,lr_list,batch_size_list,dropout_list) for _ in range(population_size)]\n    \n    for generation in range(generations):\n        print(f\"Generation {generation + 1}\")\n        scores = []\n        for chromosome in population:\n            # Evaluation of the current chromosome\n            accuracy = evaluate_model(chromosome, train_dataset, test_dataset, epochs=5)\n            scores.append(accuracy)\n            print(f\"Chromosome: {chromosome}, Accuracy: {accuracy:.2f}%\")\n        \n        # Selection of the best chromosomes (top 50 %)\n        sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n        top_chromosomes = [population[i] for i in sorted_indices[:population_size // 2]]\n        \n        # Fill the new population by crossings and mutations\n        new_population = top_chromosomes.copy()\n        while len(new_population) < population_size:\n            parent1, parent2 = random.choices(top_chromosomes, k=2)\n            child = crossover(parent1, parent2)\n            child = mutate(child,filters_list,dense_units_list,lr_list,batch_size_list,dropout_list, mutation_rate)\n            new_population.append(child)\n        \n        best_scores.append(max(scores))\n        mean_scores.append(np.mean(scores))\n        population = new_population\n\n        # Stopping criteria\n        #if max(scores) >= target_score :\n            #break\n\n    plt.figure(\"Best score for each generation\")\n    plt.plot(best_scores)\n    plt.xlabel(\"generations\")\n    plt.ylabel(\"best scores\")\n    plt.grid()\n\n    plt.figure(\"Mean score for each generation\")\n    plt.plot(mean_scores)\n    plt.xlabel(\"generations\")\n    plt.ylabel(\"mean scores\")\n    plt.grid()\n    \n    # Return the best chromosome\n    best_chromosome = population[sorted_indices[0]]\n    return best_chromosome","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:17:32.467176Z","iopub.execute_input":"2025-03-07T03:17:32.467556Z","iopub.status.idle":"2025-03-07T03:17:32.495391Z","shell.execute_reply.started":"2025-03-07T03:17:32.467489Z","shell.execute_reply":"2025-03-07T03:17:32.493913Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Description of the functions :\n\n* initialize_chromosome : returns a chromosome with parameters randomly selected within the available ones.\n* crossover : returns a chromosome whose parameters are randomly, uniformly selected among the 2 parents parameters.\n* mutation : randomly modifies each gene of a chromosome (with another available parameter) with a probability of mutation_rate.\n* evaluate : evaluates a given chromosome (the criterion being the cross entropy loss) and returns a score.","metadata":{}},{"cell_type":"markdown","source":"## Summary of the Genetic Algorithm workflow\n1. Initialization : Create an initial population of random chromosomes.\n2. Evaluation : Train and evaluate a CNN model for each chromosome.\n3. Selection : Select the best-performing chromosomes (half of the population).\n4. Crossover : Create new chromosomes by combining traits from the selected chromosomes.\n5. Mutation : Introduce random changes to the new chromosomes.\n6. Repeat : Repeat steps 2–5 for a fixed number of generations or until a stopping condition is met.\n7. Output : Return the best set of hyperparameters found.","metadata":{}},{"cell_type":"code","source":"################################## USE CASE ##################################\n\nbest_hparams = genetic_algorithm(train_dataset, test_dataset,filters_list,dense_units_list,lr_list,batch_size_list,dropout_list, population_size=5, generations=4, mutation_rate=0.1)\nprint(\"Meilleurs hyperparamètres trouvés :\", round(best_hparams,4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T03:17:32.496705Z","iopub.execute_input":"2025-03-07T03:17:32.497113Z","execution_failed":"2025-03-07T05:38:14.675Z"}},"outputs":[{"name":"stdout","text":"Generation 1\nChromosome: {'filters': 16, 'dense_units': 64, 'lr': 0.0001, 'batch_size': 16, 'dropout': 0.5}, Accuracy: 80.29%\nChromosome: {'filters': 32, 'dense_units': 128, 'lr': 0.01, 'batch_size': 64, 'dropout': 0.5}, Accuracy: 62.50%\nChromosome: {'filters': 16, 'dense_units': 64, 'lr': 0.1, 'batch_size': 16, 'dropout': 0.3}, Accuracy: 62.50%\nChromosome: {'filters': 16, 'dense_units': 32, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}, Accuracy: 77.56%\nChromosome: {'filters': 64, 'dense_units': 32, 'lr': 0.1, 'batch_size': 16, 'dropout': 0.2}, Accuracy: 62.50%\nGeneration 2\nChromosome: {'filters': 16, 'dense_units': 64, 'lr': 0.0001, 'batch_size': 16, 'dropout': 0.5}, Accuracy: 76.44%\nChromosome: {'filters': 16, 'dense_units': 32, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}, Accuracy: 71.96%\nChromosome: {'filters': 16, 'dense_units': 32, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}, Accuracy: 78.69%\nChromosome: {'filters': 32, 'dense_units': 64, 'lr': 0.0001, 'batch_size': 16, 'dropout': 0.5}, Accuracy: 76.12%\nChromosome: {'filters': 16, 'dense_units': 64, 'lr': 0.0001, 'batch_size': 16, 'dropout': 0.0}, Accuracy: 81.09%\nGeneration 3\nChromosome: {'filters': 16, 'dense_units': 64, 'lr': 0.0001, 'batch_size': 16, 'dropout': 0.0}, Accuracy: 75.48%\nChromosome: {'filters': 16, 'dense_units': 32, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}, Accuracy: 76.76%\nChromosome: {'filters': 16, 'dense_units': 64, 'lr': 0.0001, 'batch_size': 32, 'dropout': 0.0}, Accuracy: 78.69%\nChromosome: {'filters': 16, 'dense_units': 32, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}, Accuracy: 78.85%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"Due tu the limited sessions on kaggle, I couldnt finish to run the algorithm in its entierty in one session. By using the previous generations, I will \"manually\" re-start the algorithm from where it stopped :","metadata":{}},{"cell_type":"code","source":"# Best chromosomes from the 2nd generation\nparent1 = {'filters': 16, 'dense_units': 32, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\nparent2 = {'filters': 16, 'dense_units': 64, 'lr': 0.0001, 'batch_size': 16, 'dropout': 0.0}\n# Missing chromosome from the 3rd generation\nchild = crossover(parent1, parent2)\nchild = mutate(child,filters_list,dense_units_list,lr_list,batch_size_list,dropout_list, 0.1)\nchild_accuracy = evaluate_model(child, train_dataset, test_dataset, epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T06:42:05.504833Z","iopub.execute_input":"2025-03-07T06:42:05.505200Z","iopub.status.idle":"2025-03-07T06:49:28.554999Z","shell.execute_reply.started":"2025-03-07T06:42:05.505171Z","shell.execute_reply":"2025-03-07T06:49:28.553727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Chromosome: {child}, Accuracy: {child_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-07T07:20:44.374208Z","iopub.execute_input":"2025-03-07T07:20:44.374572Z","iopub.status.idle":"2025-03-07T07:20:44.380104Z","shell.execute_reply.started":"2025-03-07T07:20:44.374545Z","shell.execute_reply":"2025-03-07T07:20:44.379111Z"}},"outputs":[{"name":"stdout","text":"Chromosome: {'filters': 16, 'dense_units': 64, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.0}, Accuracy: 74.04%\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"best_scores = [80.29, 81.09, 78.85]\nmean_scores = [np.mean([80.29,62.50,62.50,77.56,62.50]),np.mean([76.44,71.96,78.69,76.12,81.09]),np.mean([75.48, 76.76, 78.69, 78.85,74.04 ])]\ngenerations = [4, 5]\npopulation_size = 5\n# Generation of the 4th generation, based on the best 3rd generation parents\ngen3_parent1 = {'filters': 16, 'dense_units': 64, 'lr': 0.0001, 'batch_size': 32, 'dropout': 0.0}\ngen3_parent2 = {'filters': 16, 'dense_units': 32, 'lr': 0.001, 'batch_size': 16, 'dropout': 0.3}\nchild3 = crossover(gen3_parent1, gen3_parent2)\nchild3 = mutate(child3,filters_list,dense_units_list,lr_list,batch_size_list,dropout_list, 0.1)\nchild4 = crossover(gen3_parent1, gen3_parent2)\nchild4 = mutate(child4,filters_list,dense_units_list,lr_list,batch_size_list,dropout_list, 0.1)\nchild5 = crossover(gen3_parent1, gen3_parent2)\nchild5 = mutate(child5,filters_list,dense_units_list,lr_list,batch_size_list,dropout_list, 0.1)\n\npopulation = [gen3_parent1, gen3_parent2, child3, child4, child5]\n\n# We finish to run the algorithm, for the 4th and 5th generation\nfor generation in generations:\n    print(f\"Generation {generation}\")\n    scores = []\n    for chromosome in population:\n        # Evaluation of the current chromosome\n        accuracy = evaluate_model(chromosome, train_dataset, test_dataset, epochs=5)\n        scores.append(accuracy)\n        print(f\"Chromosome: {chromosome}, Accuracy: {accuracy:.2f}%\")\n        \n    # Selection of the best chromosomes (top 50 %)\n    sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n    top_chromosomes = [population[i] for i in sorted_indices[:population_size // 2]]\n        \n    # Fill the new population by crossings and mutations\n    new_population = top_chromosomes.copy()\n    while len(new_population) < population_size:\n        parent1, parent2 = random.choices(top_chromosomes, k=2)\n        child = crossover(parent1, parent2)\n        child = mutate(child,filters_list,dense_units_list,lr_list,batch_size_list,dropout_list, mutation_rate)\n        new_population.append(child)\n        \n    best_scores.append(max(scores))\n    mean_scores.append(np.mean(scores))\n    population = new_population\n\n    # Stopping criteria\n    #if max(scores) >= target_score :\n        #break\n\nplt.figure(\"Best score for each generation\")\nplt.plot(best_scores)\nplt.xlabel(\"generations\")\nplt.ylabel(\"best scores\")\nplt.grid()\n\nplt.figure(\"Mean score for each generation\")\nplt.plot(mean_scores)\nplt.xlabel(\"generations\")\nplt.ylabel(\"mean scores\")\nplt.grid()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}